{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import uuid\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import faiss\n",
    "from dataclasses import dataclass, field\n",
    "import plotly.express as px\n",
    "import google.generativeai as genai\n",
    "from mistralai import Mistral\n",
    "\n",
    "GENAI_MODELS = {}\n",
    "MISTRAL_CLIENT = None\n",
    "\n",
    "def get_mistral_client():\n",
    "    global MISTRAL_CLIENT\n",
    "    if MISTRAL_CLIENT is None:\n",
    "        api_key = MISTRAL_API_KEY\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\"MISTRAL_API_KEY missing in secrets\")\n",
    "        MISTRAL_CLIENT = Mistral(api_key=api_key)\n",
    "    return MISTRAL_CLIENT\n",
    "\n",
    "def call_llm_gemini(prompt: str, model: str, timeout: int = 60) -> str:\n",
    "    try:\n",
    "        if model not in GENAI_MODELS:\n",
    "            api_key = GOOGLE_API_KEY\n",
    "            if not api_key:\n",
    "                raise RuntimeError(\"GOOGLE_API_KEY missing in secrets\")\n",
    "            genai.configure(api_key=api_key)\n",
    "            GENAI_MODELS[model] = genai.GenerativeModel(model)\n",
    "        resp = GENAI_MODELS[model].generate_content(prompt)\n",
    "        return (getattr(resp, \"text\", \"\") or \"\").strip()\n",
    "    except Exception as e:\n",
    "        logger.error(\"[Gemini %s] call failed: %s\", model, e)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Basic logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"resume_ranker_app\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Configuration dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "@dataclass\n",
    "class Weights:\n",
    "    dense: float = 0.15\n",
    "    keyword: float = 0.05\n",
    "    skill: float = 0.45\n",
    "    experience: float = 0.20\n",
    "    domain: float = 0.15\n",
    "    recency: float = 0.10\n",
    "    metadata: float = 0.05\n",
    "    projects: float = 0.05\n",
    "    education: float = 0.05\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    llm_model: str = \"llama3.2:3b-instruct-q4_K_M\"\n",
    "    llm_base_url: str = \"http://127.0.0.1:11434\"\n",
    "    embed_model: str = \"BAAI/bge-large-en-v1.5\"\n",
    "    embed_batch: int = 32\n",
    "    weights: Weights = field(default_factory=Weights)\n",
    "    bm25_min_doc_freq: int = 1\n",
    "\n",
    "cfg = PipelineConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Cached resource loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "@st.cache_resource\n",
    "def load_main_embedder(model_name: str = None):\n",
    "    model = model_name or cfg.embed_model\n",
    "    device = \"cuda\" if __import__(\"torch\").cuda.is_available() else \"cpu\"\n",
    "    logger.info(\"Loading main embedder '%s' on device=%s\", model, device)\n",
    "    return SentenceTransformer(model, device=device)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_skill_embedder(model_name: str = \"BAAI/bge-small-en-v1.5\"):\n",
    "    # keep skill embedder on CPU to conserve GPU memory\n",
    "    device = \"cpu\"\n",
    "    logger.info(\"Loading skill embedder '%s' on device=%s\", model_name, device)\n",
    "    return SentenceTransformer(model_name, device=device)\n",
    "\n",
    "@st.cache_resource\n",
    "def create_faiss_index(dim: int):\n",
    "    logger.info(\"Initializing FAISS IndexFlatIP (dim=%s)\", dim)\n",
    "    return faiss.IndexFlatIP(dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Hybrid Skill Normalizer (uses cached skill embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "class HybridSkillNormalizer:\n",
    "    def __init__(self, llm_model: str = None, embed_model: str = None, threshold: float = 0.82):\n",
    "        self.llm_model = llm_model or cfg.llm_model\n",
    "        self.threshold = threshold\n",
    "        embed_model = embed_model or \"BAAI/bge-small-en-v1.5\"\n",
    "        self.embedder = load_skill_embedder(embed_model)\n",
    "        self.cache: Dict[str, np.ndarray] = {}\n",
    "        self.alias_map: Dict[str, str] = {}\n",
    "        self.reverse_groups: Dict[str, List[str]] = {}\n",
    "\n",
    "    def _llm_normalize(self, skill: str) -> str:\n",
    "        prompt = f\"Normalize the following skill into a concise canonical skill token. Return only the canonical skill name:\\n\\\"{skill}\\\"\"\n",
    "        try:\n",
    "            if not getattr(cfg, \"llm_base_url\", None):\n",
    "                return skill.strip().lower()\n",
    "            url = cfg.llm_base_url.rstrip(\"/\") + \"/api/chat\"\n",
    "            payload = {\"model\": self.llm_model, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"stream\": False}\n",
    "            r = httpx.post(url, json=payload, timeout=20)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            out = \"\"\n",
    "            if isinstance(data, dict):\n",
    "                if \"message\" in data and isinstance(data[\"message\"], dict):\n",
    "                    out = data[\"message\"].get(\"content\", \"\")\n",
    "                elif \"response\" in data:\n",
    "                    out = data.get(\"response\", \"\")\n",
    "                else:\n",
    "                    out = str(data)\n",
    "            else:\n",
    "                out = str(data)\n",
    "            out = out.splitlines()[0].strip().lower()\n",
    "            out = re.sub(r\"[^a-z0-9_\\-\\s\\.]+\", \"\", out)\n",
    "            if out == \"\":\n",
    "                return skill.strip().lower()\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            logger.debug(\"LLM normalization failed for '%s': %s\", skill, e)\n",
    "            return skill.strip().lower()\n",
    "\n",
    "    def _embed(self, text: str) -> np.ndarray:\n",
    "        v = self.embedder.encode([text], normalize_embeddings=True)\n",
    "        return np.asarray(v[0], dtype=np.float32)\n",
    "\n",
    "    def _find_similar(self, vec: np.ndarray):\n",
    "        if not self.cache:\n",
    "            return None, 0.0\n",
    "        keys = list(self.cache.keys())\n",
    "        mat = np.vstack([self.cache[k] for k in keys])\n",
    "        sims = util.cos_sim(vec, mat)[0]\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        return keys[best_idx], float(sims[best_idx])\n",
    "\n",
    "    def normalize_skill(self, s: str) -> str:\n",
    "        if not s or not isinstance(s, str):\n",
    "            return \"\"\n",
    "        original = s.strip().lower()\n",
    "        if original in self.alias_map:\n",
    "            return self.alias_map[original]\n",
    "        cleaned = self._llm_normalize(original)\n",
    "        vec = self._embed(cleaned)\n",
    "        best, score = self._find_similar(vec)\n",
    "        if best and score >= self.threshold:\n",
    "            self.alias_map[original] = best\n",
    "            self.reverse_groups.setdefault(best, []).append(original)\n",
    "            return best\n",
    "        self.cache[cleaned] = vec\n",
    "        self.alias_map[original] = cleaned\n",
    "        self.reverse_groups.setdefault(cleaned, []).append(original)\n",
    "        return cleaned\n",
    "\n",
    "    def normalize_list(self, skills: List[str]) -> List[str]:\n",
    "        out: List[str] = []\n",
    "        seen = set()\n",
    "        for s in skills or []:\n",
    "            if not isinstance(s, str):\n",
    "                continue\n",
    "            try:\n",
    "                canon = self.normalize_skill(s)\n",
    "            except Exception:\n",
    "                canon = s.strip().lower()\n",
    "            if canon and canon not in seen:\n",
    "                seen.add(canon)\n",
    "                out.append(canon)\n",
    "        return out\n",
    "\n",
    "@st.cache_resource\n",
    "def get_skill_normalizer():\n",
    "    return HybridSkillNormalizer(embed_model=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "SKILL_NORMALIZER: HybridSkillNormalizer = get_skill_normalizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Document reading helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def read_document(blob: Dict[str, Any]) -> str:\n",
    "    name = blob.get(\"name\", \"\").lower()\n",
    "    data = blob.get(\"bytes\", b\"\")\n",
    "    if not data:\n",
    "        return \"\"\n",
    "    if name.endswith(\".txt\"):\n",
    "        try:\n",
    "            return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            return data.decode(\"latin-1\", errors=\"ignore\")\n",
    "    if name.endswith(\".pdf\"):\n",
    "        try:\n",
    "            stream = io.BytesIO(data)\n",
    "            reader = PdfReader(stream)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += (page.extract_text() or \"\") + \"\\n\"\n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            logger.warning(\"PDF extraction error for %s: %s\", name, e)\n",
    "            return \"\"\n",
    "    try:\n",
    "        return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# LLM call helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def call_llm(prompt: str, model: str = None, timeout: int = 60) -> str:\n",
    "    model = model or cfg.llm_model\n",
    "    url = cfg.llm_base_url.rstrip(\"/\") + \"/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"num_predict\": 512, \"temperature\": 0.1, \"top_p\": 0.9},\n",
    "    }\n",
    "    try:\n",
    "        r = httpx.post(url, json=payload, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        if isinstance(data, dict):\n",
    "            if \"message\" in data and isinstance(data[\"message\"], dict):\n",
    "                return data[\"message\"].get(\"content\", \"\")\n",
    "            if \"response\" in data:\n",
    "                return data[\"response\"]\n",
    "        return str(data)\n",
    "    except Exception as e:\n",
    "        logger.error(\"[LLM] call failed: %s\", e)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Safe JSON extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def safe_json_extract(raw: str) -> Dict[str, Any]:\n",
    "    if not raw:\n",
    "        return {}\n",
    "    raw = raw.strip()\n",
    "    if raw.startswith(\"```\"):\n",
    "        lines = []\n",
    "        for line in raw.splitlines():\n",
    "            if line.strip().startswith(\"```\"):\n",
    "                continue\n",
    "            lines.append(line)\n",
    "        raw = \"\\n\".join(lines)\n",
    "    start = raw.find(\"{\")\n",
    "    end = raw.rfind(\"}\")\n",
    "    if start >= 0 and end > start:\n",
    "        candidate = raw[start : end + 1]\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except Exception:\n",
    "            try:\n",
    "                fixed = candidate.replace(\"'\", '\"')\n",
    "                fixed = re.sub(r\",\\s*}\", \"}\", fixed)\n",
    "                fixed = re.sub(r\",\\s*]\", \"]\", fixed)\n",
    "                return json.loads(fixed)\n",
    "            except Exception:\n",
    "                return {}\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Job extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def extract_job_struct(text: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "You are a JSON extractor. From the job posting text below extract a JSON object with fields:\n",
    "- job_title (string)\n",
    "- summary (short string)\n",
    "- must (list of strings)\n",
    "- important (list of strings)\n",
    "- nice (list of strings)\n",
    "- implicit (list of strings)\n",
    "- domain (list of domains/tags)\n",
    "\n",
    "Return only valid JSON. Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    raw = call_llm_gemini(prompt, model=cfg.llm_model_resume, timeout=90)\n",
    "    parsed = safe_json_extract(raw)\n",
    "    raw_tiers = {\n",
    "        \"must\": parsed.get(\"must\", parsed.get(\"must_have\", [])) or [],\n",
    "        \"important\": parsed.get(\"important\", parsed.get(\"important_skills\", [])) or [],\n",
    "        \"nice\": parsed.get(\"nice\", parsed.get(\"nice_to_have\", [])) or [],\n",
    "        \"implicit\": parsed.get(\"implicit\", []) or [],\n",
    "    }\n",
    "    norm_tiers = {tier: SKILL_NORMALIZER.normalize_list(raw_tiers.get(tier, [])) for tier in [\"must\", \"important\", \"nice\", \"implicit\"]}\n",
    "    return {\n",
    "        \"job_title\": parsed.get(\"job_title\", \"\").strip(),\n",
    "        \"summary\": parsed.get(\"summary\", \"\").strip(),\n",
    "        \"must\": norm_tiers[\"must\"],\n",
    "        \"important\": norm_tiers[\"important\"],\n",
    "        \"nice\": norm_tiers[\"nice\"],\n",
    "        \"implicit\": norm_tiers[\"implicit\"],\n",
    "        \"domain\": parsed.get(\"domain\", []) or [],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Basic regex resume parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "EMAIL_RE = re.compile(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\")\n",
    "YEARS_RE = re.compile(r\"(\\d{4})[\u2013-](\\d{4}|present|Present|Now|now)\")\n",
    "\n",
    "def regex_extract_basic(text: str) -> Dict[str, Any]:\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "    name = \"\"\n",
    "    if lines:\n",
    "        first = lines[0]\n",
    "        if len(first.split()) <= 4 and re.search(r\"[A-Za-z]\", first):\n",
    "            name = first\n",
    "        else:\n",
    "            for i, ln in enumerate(lines):\n",
    "                if EMAIL_RE.search(ln) and i > 0:\n",
    "                    name = lines[i - 1]\n",
    "                    break\n",
    "    email_match = EMAIL_RE.search(text)\n",
    "    email = email_match.group(0) if email_match else \"\"\n",
    "    skill_candidates = set()\n",
    "    for ln in lines:\n",
    "        if re.search(r\"\\b(Skill|Skills|TECH|TECHNICAL|Technologies)\\b\", ln, re.I) or (\",\" in ln and len(ln.split(\",\")) <= 15):\n",
    "            for token in re.split(r\"[,:;\\|\\n]\", ln):\n",
    "                token = token.strip()\n",
    "                if token and len(token) < 60:\n",
    "                    skill_candidates.add(token)\n",
    "    yrs = 0.0\n",
    "    years = YEARS_RE.findall(text)\n",
    "    if years:\n",
    "        tot = 0\n",
    "        count = 0\n",
    "        for s, e in years:\n",
    "            try:\n",
    "                sy = int(s)\n",
    "                ey = datetime.utcnow().year if re.match(r\"(?i)present|now\", e) else int(e)\n",
    "                tot += max(0, ey - sy)\n",
    "                count += 1\n",
    "            except:\n",
    "                pass\n",
    "        if count:\n",
    "            yrs = tot / count\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"email\": email,\n",
    "        \"skills\": sorted(list(skill_candidates))[:200],\n",
    "        \"years_est\": yrs,\n",
    "        \"raw\": text,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# LLM-based resume extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def extract_resume_struct(text: str, use_llm=True) -> Dict[str, Any]:\n",
    "    basic = regex_extract_basic(text)\n",
    "    if use_llm:\n",
    "        prompt = f\"\"\"\n",
    "You are an extractor. Given the resume text, return a JSON with:\n",
    "- name\n",
    "- email\n",
    "- skills (list of strings)\n",
    "- experience (list of {{company, title, start, end, years}})\n",
    "- projects (list of short descriptions)\n",
    "- domain (list of tags)\n",
    "- last_active (year or string)\n",
    "- years_est (float)\n",
    "Return only JSON. Resume:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "        raw = call_llm(prompt, model=cfg.llm_model, timeout=90)\n",
    "        parsed = safe_json_extract(raw)\n",
    "        skills = parsed.get(\"skills\") or basic.get(\"skills\") or []\n",
    "        skills = [s.strip() for s in skills if isinstance(s, str) and s.strip()]\n",
    "        skills = SKILL_NORMALIZER.normalize_list(skills)\n",
    "        skills_bool = {s: True for s in skills}\n",
    "        return {\n",
    "            \"name\": parsed.get(\"name\") or basic.get(\"name\") or \"\",\n",
    "            \"email\": parsed.get(\"email\") or basic.get(\"email\") or \"\",\n",
    "            \"skills\": skills,\n",
    "            \"skills_bool\": skills_bool,\n",
    "            \"experience\": parsed.get(\"experience\", []),\n",
    "            \"projects\": parsed.get(\"projects\", []),\n",
    "            \"domain\": parsed.get(\"domain\", []),\n",
    "            \"last_active\": parsed.get(\"last_active\") or \"\",\n",
    "            \"years_est\": parsed.get(\"years_est\") or basic.get(\"years_est\") or 0,\n",
    "            \"raw\": text,\n",
    "        }\n",
    "    else:\n",
    "        skills = SKILL_NORMALIZER.normalize_list(basic.get(\"skills\", []))\n",
    "        return {\n",
    "            \"name\": basic.get(\"name\", \"\"),\n",
    "            \"email\": basic.get(\"email\", \"\"),\n",
    "            \"skills\": skills,\n",
    "            \"skills_bool\": {s: True for s in skills},\n",
    "            \"experience\": [],\n",
    "            \"projects\": [],\n",
    "            \"domain\": [],\n",
    "            \"last_active\": \"\",\n",
    "            \"years_est\": basic.get(\"years_est\", 0),\n",
    "            \"raw\": text,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Embedding + FAISS services (cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "class EmbeddingService:\n",
    "    def __init__(self, model_name: str = None):\n",
    "        model_name = model_name or cfg.embed_model\n",
    "        self.model = load_main_embedder(model_name)\n",
    "        self.dim = self.model.get_sentence_embedding_dimension()\n",
    "        logger.info(\"Embedding dim: %s\", self.dim)\n",
    "        self._faiss_index = None\n",
    "\n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        if not texts:\n",
    "            return np.zeros((0, self.dim), dtype=np.float32)\n",
    "        vecs = self.model.encode(texts, batch_size=cfg.embed_batch, convert_to_numpy=True, normalize_embeddings=True)\n",
    "        return vecs.astype(np.float32)\n",
    "\n",
    "    def create_faiss(self):\n",
    "        if self._faiss_index is None:\n",
    "            self._faiss_index = create_faiss_index(self.dim)\n",
    "        return self._faiss_index\n",
    "\n",
    "@st.cache_resource\n",
    "def get_embedding_service():\n",
    "    return EmbeddingService(cfg.embed_model)\n",
    "\n",
    "EMB: EmbeddingService = get_embedding_service()\n",
    "\n",
    "class FAISSService:\n",
    "    def __init__(self, dim: int):\n",
    "        self.dim = dim\n",
    "        self.index = create_faiss_index(dim)\n",
    "        self.ids: List[str] = []\n",
    "        self.meta: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = create_faiss_index(self.dim)\n",
    "        self.ids = []\n",
    "        self.meta = {}\n",
    "\n",
    "    def add(self, vectors: np.ndarray, payloads: List[Dict[str, Any]]):\n",
    "        if vectors is None or vectors.shape[0] == 0:\n",
    "            return\n",
    "        vecs = np.asarray(vectors, dtype=np.float32)\n",
    "        if vecs.ndim == 1:\n",
    "            vecs = vecs.reshape(1, -1)\n",
    "        self.index.add(vecs)\n",
    "        for p in payloads:\n",
    "            self.ids.append(p[\"id\"])\n",
    "            self.meta[p[\"id\"]] = p\n",
    "\n",
    "    def search(self, query_vec: np.ndarray, top_k: int = 10):\n",
    "        if self.index.ntotal == 0:\n",
    "            return []\n",
    "        q = np.asarray(query_vec, dtype=np.float32).reshape(1, -1)\n",
    "        D, I = self.index.search(q, top_k)\n",
    "        hits = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            # Guard against invalid indices that can appear in FAISS results\n",
    "            if idx < 0 or idx >= len(self.ids):\n",
    "                continue\n",
    "            rid = self.ids[idx]\n",
    "            hits.append({\"id\": rid, \"payload\": self.meta.get(rid, {}), \"score\": float(score)})\n",
    "        return hits\n",
    "\n",
    "FA = FAISSService(EMB.dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# BM25 helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def safe_build_bm25(docs: List[str]):\n",
    "    try:\n",
    "        tokenized = [re.findall(r\"\\w+\", d.lower()) for d in docs]\n",
    "        if not any(tokenized):\n",
    "            return None\n",
    "        return BM25Okapi(tokenized)\n",
    "    except Exception as e:\n",
    "        logger.warning(\"BM25 build failed: %s\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Scoring helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def normalize_scores(raw: List[float]) -> List[float]:\n",
    "    arr = np.array(raw, dtype=np.float32)\n",
    "    if arr.size == 0:\n",
    "        return []\n",
    "    minv, maxv = float(np.min(arr)), float(np.max(arr))\n",
    "    if abs(maxv - minv) < 1e-9:\n",
    "        return [1.0 for _ in arr.tolist()]\n",
    "    norm = (arr - minv) / (maxv - minv)\n",
    "    return norm.tolist()\n",
    "\n",
    "def skill_tier_score(candidate_skills: List[str], job_tiers: Dict[str, List[str]]) -> float:\n",
    "    if not candidate_skills:\n",
    "        return 0.0\n",
    "    cand = {SKILL_NORMALIZER.normalize_skill(s) for s in candidate_skills if s}\n",
    "    cand.discard(\"\")\n",
    "    must = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"must\", []))\n",
    "    imp = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"important\", []))\n",
    "    nice = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"nice\", []))\n",
    "    impl = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"implicit\", []))\n",
    "    tier_weights = {\"must\": 1.0, \"important\": 0.7, \"nice\": 0.3, \"implicit\": 0.15}\n",
    "    def coverage(tier_skills: List[str]) -> float:\n",
    "        if not tier_skills:\n",
    "            return 0.0\n",
    "        present = sum(1.0 for s in tier_skills if s in cand)\n",
    "        return present / max(1, len(tier_skills))\n",
    "    must_cov = coverage(must)\n",
    "    imp_cov = coverage(imp)\n",
    "    nice_cov = coverage(nice)\n",
    "    impl_cov = coverage(impl)\n",
    "    total_weight = ((tier_weights[\"must\"] if must else 0.0) + (tier_weights[\"important\"] if imp else 0.0) + (tier_weights[\"nice\"] if nice else 0.0) + (tier_weights[\"implicit\"] if impl else 0.0))\n",
    "    if total_weight <= 0:\n",
    "        base_score = 0.0\n",
    "    else:\n",
    "        base_score = (must_cov * tier_weights[\"must\"] + imp_cov * tier_weights[\"important\"] + nice_cov * tier_weights[\"nice\"] + impl_cov * tier_weights[\"implicit\"]) / total_weight\n",
    "    if must:\n",
    "        missing = sum(1 for s in must if s not in cand)\n",
    "        missing_fraction = missing / max(1, len(must))\n",
    "        penalty = 0.5 * missing_fraction\n",
    "        final_score = base_score * (1.0 - penalty)\n",
    "    else:\n",
    "        final_score = base_score\n",
    "    return float(max(min(final_score, 1.0), 0.0))\n",
    "\n",
    "def domain_score(candidate_domains: List[str], job_domains: List[str]) -> float:\n",
    "    if not job_domains:\n",
    "        return 0.0\n",
    "    c = {d.lower() for d in (candidate_domains or [])}\n",
    "    j = {d.lower() for d in (job_domains or [])}\n",
    "    if not j:\n",
    "        return 0.0\n",
    "    return len(c & j) / max(1, len(j))\n",
    "\n",
    "def experience_score(years: float) -> float:\n",
    "    return min(max(float(years or 0), 0.0) / 10.0, 1.0)\n",
    "\n",
    "def recency_score(last_active) -> float:\n",
    "    try:\n",
    "        y = int(str(last_active).strip())\n",
    "        gap = max(0, datetime.utcnow().year - y)\n",
    "        if gap <= 1:\n",
    "            return 1.0\n",
    "        if gap <= 3:\n",
    "            return 0.8\n",
    "        if gap <= 5:\n",
    "            return 0.5\n",
    "        return 0.2\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "def metadata_score(structured: Dict[str, Any]) -> float:\n",
    "    score = 0.0\n",
    "    score += 0.5 if structured.get(\"email\") else 0.0\n",
    "    score += 0.5 if structured.get(\"projects\") else 0.0\n",
    "    return min(score, 1.0)\n",
    "\n",
    "def projects_score(structured: Dict[str, Any]) -> float:\n",
    "    projects = structured.get(\"projects\") or []\n",
    "    if not projects:\n",
    "        return 0.0\n",
    "    n = len(projects)\n",
    "    return float(min(n / 5.0, 1.0))\n",
    "\n",
    "def education_score(structured: Dict[str, Any]) -> float:\n",
    "    text = (structured.get(\"raw\") or \"\") + \"\\n\" + \" \".join(structured.get(\"projects\", []))\n",
    "    text = text.lower()\n",
    "    if \"phd\" in text or \"ph.d\" in text:\n",
    "        return 1.0\n",
    "    if \"master\" in text or \"msc\" in text or \"m.sc\" in text:\n",
    "        return 0.8\n",
    "    if \"bachelor\" in text or \"bsc\" in text or \"b.sc\" in text:\n",
    "        return 0.6\n",
    "    if \"diploma\" in text or \"associate\" in text:\n",
    "        return 0.4\n",
    "    return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def generate_explanation(job_struct: Dict[str, Any], candidate: Dict[str, Any], components: Dict[str, float]) -> Dict[str, Any]:\n",
    "    job_tiers = {\n",
    "        \"must\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"must\", [])),\n",
    "        \"important\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"important\", [])),\n",
    "        \"nice\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"nice\", [])),\n",
    "        \"implicit\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"implicit\", [])),\n",
    "    }\n",
    "    structured = candidate.get(\"structured\", candidate)\n",
    "    cand_skills = SKILL_NORMALIZER.normalize_list(structured.get(\"skills\", []))\n",
    "    cand_set = set(cand_skills)\n",
    "    strengths = sorted([s for s in job_tiers.get(\"must\", []) if s in cand_set])\n",
    "    gaps = sorted([s for s in job_tiers.get(\"must\", []) if s not in cand_set])\n",
    "    projects = structured.get(\"projects\", [])\n",
    "    exp_summary = f\"{structured.get('years_est', 0)} years; last active: {structured.get('last_active','N/A')}\"\n",
    "    breakdown = components\n",
    "    weight_table = {\n",
    "        \"dense\": cfg.weights.dense,\n",
    "        \"keyword\": cfg.weights.keyword,\n",
    "        \"skill\": cfg.weights.skill,\n",
    "        \"experience\": cfg.weights.experience,\n",
    "        \"domain\": cfg.weights.domain,\n",
    "        \"recency\": cfg.weights.recency,\n",
    "        \"projects\": cfg.weights.projects,\n",
    "        \"education\": cfg.weights.education,\n",
    "        \"metadata\": cfg.weights.metadata,\n",
    "    }\n",
    "    overall = sum(components[k] * weight_table.get(k, 0.0) for k in components)\n",
    "    if overall >= 0.75:\n",
    "        confidence = \"high\"\n",
    "    elif overall >= 0.5:\n",
    "        confidence = \"medium\"\n",
    "    else:\n",
    "        confidence = \"low\"\n",
    "    prompt = f\"\"\"\n",
    "You are an experienced engineer and hiring panelist reviewing a candidate's RESUME.\n",
    "The job description is context; your priority is the candidate's actual experience and how it matches this specific role.\n",
    "\n",
    "Job (context):\n",
    "- Title: {job_struct.get('job_title') or ''}\n",
    "- Summary: {job_struct.get('summary') or ''}\n",
    "\n",
    "Candidate (focus of the review):\n",
    "- Name: {structured.get('name') or candidate.get('name') or ''}\n",
    "- Normalized skills: {cand_skills}\n",
    "- Projects (from resume): {projects}\n",
    "- Experience & recency: {exp_summary}\n",
    "\n",
    "Analysis data:\n",
    "- Component scores (0\u20131): {breakdown}\n",
    "- Weights: {weight_table}\n",
    "- Overall fit score (0\u20131): {overall:.3f}\n",
    "- Job must-have strengths (present in resume): {strengths}\n",
    "- Job must-have gaps (missing from resume): {gaps}\n",
    "- Confidence bucket: {confidence}\n",
    "\n",
    "Write a short, job-specific review (3\u20135 sentences) as if you were giving feedback to a hiring manager:\n",
    "1. Describe the candidate's profile based on the RESUME (tech/domain stack, type of projects, seniority).\n",
    "2. Relate how this profile lines up with the job at a high level (strong match, partial match, or stretch) for THIS specific role.\n",
    "3. Explicitly mention 2\u20134 concrete strengths from their resume and 1\u20132 key gaps relevant to the job.\n",
    "4. Mention the overall fit score (0\u20131) and confidence level ({confidence}) in a natural way.\n",
    "Avoid boilerplate phrases and be concise.\n",
    "\"\"\"\n",
    "    human_text = call_llm_gemini(prompt, model=cfg.llm_model_explain, timeout=45)\n",
    "    structured_out = {\n",
    "        \"strengths\": strengths,\n",
    "        \"gaps\": gaps,\n",
    "        \"experience_summary\": exp_summary,\n",
    "        \"projects\": projects,\n",
    "        \"score_breakdown\": breakdown,\n",
    "        \"weights\": weight_table,\n",
    "        \"overall\": float(overall),\n",
    "        \"confidence\": confidence,\n",
    "    }\n",
    "    return {\"structured\": structured_out, \"human\": human_text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Ranking pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def rank_hybrid(job: Dict[str, Any], resumes: List[Dict[str, Any]], cfg: PipelineConfig, top_n: int = 10):\n",
    "    resume_texts = [r[\"raw\"] for r in resumes]\n",
    "    resume_vecs = EMB.encode(resume_texts) if len(resume_texts) else np.zeros((0, EMB.dim), dtype=np.float32)\n",
    "    job_vec = EMB.encode([job[\"raw\"]])[0] if job[\"raw\"].strip() else np.zeros((EMB.dim,), dtype=np.float32)\n",
    "    FA.reset()\n",
    "    payloads = [{\"id\": r[\"id\"], \"structured\": r[\"structured\"], \"skills\": r.get(\"skills\", [])} for r in resumes]\n",
    "    FA.add(resume_vecs, payloads)\n",
    "    dense_raw = [0.0] * len(resumes)\n",
    "    hits = FA.search(job_vec, top_k=len(resumes))\n",
    "    id2idx = {r[\"id\"]: i for i, r in enumerate(resumes)}\n",
    "    for h in hits:\n",
    "        idx = id2idx.get(h[\"id\"])\n",
    "        if idx is not None:\n",
    "            dense_raw[idx] = h[\"score\"]\n",
    "    dense_norm = normalize_scores(dense_raw)\n",
    "    bm25 = safe_build_bm25(resume_texts)\n",
    "    if bm25:\n",
    "        job_tokens = re.findall(r\"\\w+\", job[\"raw\"].lower())\n",
    "        bm_raw = bm25.get_scores(job_tokens)\n",
    "    else:\n",
    "        bm_raw = [0.0] * len(resumes)\n",
    "    skill_raw, domain_raw, exp_raw, rec_raw, proj_raw, edu_raw, meta_raw = [], [], [], [], [], [], []\n",
    "    for r in resumes:\n",
    "        structured = r.get(\"structured\", {})\n",
    "        s = skill_tier_score(structured.get(\"skills\", []), {\n",
    "            \"must\": job[\"structured\"].get(\"must\", []),\n",
    "            \"important\": job[\"structured\"].get(\"important\", []),\n",
    "            \"nice\": job[\"structured\"].get(\"nice\", []),\n",
    "            \"implicit\": job[\"structured\"].get(\"implicit\", []),\n",
    "        })\n",
    "        d = domain_score(r.get(\"domain\", []), job[\"structured\"].get(\"domain\", []))\n",
    "        e = experience_score(r.get(\"years_est\", 0) or 0)\n",
    "        rc = recency_score(r.get(\"last_active\", \"\")) if r.get(\"last_active\") else recency_score(r.get(\"years_est\", 0))\n",
    "        p = projects_score(structured)\n",
    "        edu = education_score(structured)\n",
    "        m = metadata_score(structured)\n",
    "        skill_raw.append(s)\n",
    "        domain_raw.append(d)\n",
    "        exp_raw.append(e)\n",
    "        rec_raw.append(rc)\n",
    "        proj_raw.append(p)\n",
    "        edu_raw.append(edu)\n",
    "        meta_raw.append(m)\n",
    "    dense = dense_norm or [0.0] * len(resumes)\n",
    "    keyword = normalize_scores(bm_norm) or [0.0] * len(resumes)\n",
    "    skill = normalize_scores(skill_raw) or [0.0] * len(resumes)\n",
    "    domain = normalize_scores(domain_raw) or [0.0] * len(resumes)\n",
    "    experience = normalize_scores(exp_raw) or [0.0] * len(resumes)\n",
    "    recency = normalize_scores(rec_raw) or [0.0] * len(resumes)\n",
    "    projects = normalize_scores(proj_raw) or [0.0] * len(resumes)\n",
    "    education = normalize_scores(edu_raw) or [0.0] * len(resumes)\n",
    "    metadata = normalize_scores(meta_raw) or [0.0] * len(resumes)\n",
    "    final = []\n",
    "    W = cfg.weights\n",
    "    for i, r in enumerate(resumes):\n",
    "        components = {\n",
    "            \"dense\": float(dense[i]),\n",
    "            \"keyword\": float(keyword[i]),\n",
    "            \"skill\": float(skill[i]),\n",
    "            \"experience\": float(experience[i]),\n",
    "            \"domain\": float(domain[i]),\n",
    "            \"recency\": float(recency[i]),\n",
    "            \"projects\": float(projects[i]),\n",
    "            \"education\": float(education[i]),\n",
    "            \"metadata\": float(metadata[i]),\n",
    "        }\n",
    "        overall = (\n",
    "            components[\"dense\"] * W.dense\n",
    "            + components[\"keyword\"] * W.keyword\n",
    "            + components[\"skill\"] * W.skill\n",
    "            + components[\"experience\"] * W.experience\n",
    "            + components[\"domain\"] * W.domain\n",
    "            + components[\"recency\"] * W.recency\n",
    "            + components[\"projects\"] * W.projects\n",
    "            + components[\"education\"] * W.education\n",
    "            + components[\"metadata\"] * W.metadata\n",
    "        )\n",
    "        expl = generate_explanation(job[\"structured\"], r, components)\n",
    "        final.append(\n",
    "            {\n",
    "                \"id\": r[\"id\"],\n",
    "                \"name\": r[\"structured\"].get(\"name\", r.get(\"name\", \"\")),\n",
    "                \"overall\": float(overall),\n",
    "                \"components\": components,\n",
    "                \"explanation\": expl,\n",
    "            }\n",
    "        )\n",
    "    final_sorted = sorted(final, key=lambda x: x[\"overall\"], reverse=True)\n",
    "    return final_sorted[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Assemble entities from uploaded blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "def assemble_entities_from_blobs(jd_blob: Dict[str, Any], resume_blobs: List[Dict[str, Any]]):\n",
    "    jd_text = read_document(jd_blob)\n",
    "    jd_struct = extract_job_struct(jd_text)\n",
    "    job = {\n",
    "        \"id\": jd_blob.get(\"name\", f\"job_{uuid.uuid4()}\"),\n",
    "        \"raw\": jd_text,\n",
    "        \"structured\": jd_struct,\n",
    "    }\n",
    "    resumes = []\n",
    "    for rb in resume_blobs:\n",
    "        txt = read_document(rb)\n",
    "        parsed = extract_resume_struct(txt)\n",
    "        resumes.append(\n",
    "            {\n",
    "                \"id\": rb.get(\"name\", f\"res_{uuid.uuid4()}\"),\n",
    "                \"raw\": txt,\n",
    "                \"skills\": parsed.get(\"skills\", []),\n",
    "                \"experiences\": parsed.get(\"experience\", []),\n",
    "                \"structured\": parsed,\n",
    "                \"name\": parsed.get(\"name\", rb.get(\"name\", \"\")),\n",
    "                \"domain\": parsed.get(\"domain\", []),\n",
    "                \"years_est\": parsed.get(\"years_est\", 0),\n",
    "                \"last_active\": parsed.get(\"last_active\", \"\"),\n",
    "            }\n",
    "        )\n",
    "    return job, resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "st.set_page_config(page_title=\"AI Resume Ranking System\", layout=\"wide\")\n",
    "st.title(\"\ud83c\udfaf Multi-Dimensional AI Resume Ranking System\")\n",
    "st.write(\"Upload a job description and resumes to generate ranked candidates\")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "col1, col2 = st.columns([1, 2])\n",
    "\n",
    "with col1:\n",
    "    st.header(\"\ud83d\udcc1 Input Files\")\n",
    "    jd_file = st.file_uploader(\"\ud83d\udcc4 Upload Job Description\", type=[\"pdf\", \"txt\"])\n",
    "    res_files = st.file_uploader(\"\ud83e\uddd1\u200d\ud83d\udcbc Upload Candidate Resumes\", type=[\"pdf\", \"txt\"], accept_multiple_files=True)\n",
    "\n",
    "    with st.expander(\"\u2699\ufe0f Advanced Settings\"):\n",
    "        top_n = st.slider(\"Top N candidates to show:\", 1, 20, 10)\n",
    "        st.write(\"LLM model:\", cfg.llm_model)\n",
    "        st.write(\"Embedding model:\", cfg.embed_model)\n",
    "        st.markdown(\"**Weighting (0.0 - 1.0)**\")\n",
    "        cfg.weights.dense = st.slider(\"Dense similarity weight\", 0.0, 1.0, cfg.weights.dense, 0.05)\n",
    "        cfg.weights.keyword = st.slider(\"BM25 keyword weight\", 0.0, 1.0, cfg.weights.keyword, 0.05)\n",
    "        cfg.weights.skill = st.slider(\"Skill tier weight\", 0.0, 1.0, cfg.weights.skill, 0.05)\n",
    "        cfg.weights.experience = st.slider(\"Experience weight\", 0.0, 1.0, cfg.weights.experience, 0.05)\n",
    "        cfg.weights.domain = st.slider(\"Domain weight\", 0.0, 1.0, cfg.weights.domain, 0.05)\n",
    "        cfg.weights.recency = st.slider(\"Recency weight\", 0.0, 1.0, cfg.weights.recency, 0.05)\n",
    "        cfg.weights.projects = st.slider(\"Projects weight\", 0.0, 1.0, cfg.weights.projects, 0.05)\n",
    "        cfg.weights.education = st.slider(\"Education weight\", 0.0, 1.0, cfg.weights.education, 0.05)\n",
    "        cfg.weights.metadata = st.slider(\"Metadata weight\", 0.0, 1.0, cfg.weights.metadata, 0.05)\n",
    "\n",
    "    run_button = st.button(\"\ud83d\ude80 Run Candidate Ranking\")\n",
    "\n",
    "with col2:\n",
    "    if run_button:\n",
    "        if not jd_file:\n",
    "            st.error(\"Please upload a job description.\")\n",
    "            st.stop()\n",
    "        if not res_files:\n",
    "            st.error(\"Please upload at least one resume.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.info(\"\u23f3 Running full hybrid pipeline (LLM extraction + embeddings + ranking)...\")\n",
    "\n",
    "        jd_blob = {\"name\": jd_file.name, \"bytes\": jd_file.read()}\n",
    "        resume_blobs = [{\"name\": f.name, \"bytes\": f.read()} for f in res_files]\n",
    "\n",
    "        try:\n",
    "            job, resumes = assemble_entities_from_blobs(jd_blob, resume_blobs)\n",
    "            ranked = rank_hybrid(job, resumes, cfg, top_n=top_n)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Pipeline failed: {e}\")\n",
    "            logger.exception(\"Pipeline error\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"\u2728 Ranking Completed!\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udccc Extracted Job Structure\")\n",
    "        st.json(job.get(\"structured\", {}))\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83c\udfc6 Ranked Candidates\")\n",
    "        df = pd.DataFrame([{\"Rank\": i + 1, \"Name\": r[\"name\"], \"Score\": round(r[\"overall\"], 3)} for i, r in enumerate(ranked)])\n",
    "        st.dataframe(df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udd0d Candidate Explanations\")\n",
    "        for i, r in enumerate(ranked):\n",
    "            with st.expander(f\"#{i+1} \u2014 {r['name']} (Score: {round(r['overall'], 3)})\"):\n",
    "                comp_items = list(r[\"components\"].items())\n",
    "                comp_df = pd.DataFrame({\"Component\": [k for k, _ in comp_items], \"Score\": [float(v) for _, v in comp_items]})\n",
    "                radar_fig = px.line_polar(comp_df, r=\"Score\", theta=\"Component\", line_close=True, range_r=[0, 1], title=\"Component Radar\")\n",
    "                radar_fig.update_traces(fill=\"toself\")\n",
    "                st.plotly_chart(radar_fig, use_container_width=True)\n",
    "\n",
    "                overall_fit = r[\"explanation\"][\"structured\"].get(\"overall\", r[\"overall\"])\n",
    "                conf = r[\"explanation\"][\"structured\"].get(\"confidence\", \"unknown\")\n",
    "                st.write(f\"**Overall fit score:** {overall_fit:.3f}\")\n",
    "                st.write(f\"**Confidence:** {conf}\")\n",
    "\n",
    "                st.markdown(\"### \ud83d\udcdd Candidate Review\")\n",
    "                st.info(r[\"explanation\"].get(\"human\", \"\"))\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udce5 Download Results\")\n",
    "        st.download_button(\"Download JSON Report\", json.dumps(ranked, indent=2, default=str), file_name=\"ranking_output.json\", mime=\"application/json\")\n",
    "        st.download_button(\"Download CSV Rankings\", df.to_csv(index=False), file_name=\"ranking_output.csv\", mime=\"text/csv\")\n",
    "\n",
    "        st.caption(\"Built with Streamlit \u2022 FAISS \u2022 BGE Embeddings \u2022 LLM Explainability\")\n",
    "\n",
    "# End of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app.py\n",
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import uuid\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from pypdf import PdfReader\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rank_bm25 import BM25Okapi\n",
    "import faiss\n",
    "from dataclasses import dataclass, field\n",
    "import plotly.express as px\n",
    "import google.generativeai as genai\n",
    "from mistralai import Mistral\n",
    "\n",
    "GENAI_MODELS = {}\n",
    "MISTRAL_CLIENT = None\n",
    "\n",
    "def get_mistral_client():\n",
    "    global MISTRAL_CLIENT\n",
    "    if MISTRAL_CLIENT is None:\n",
    "        api_key = MISTRAL_API_KEY\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\"MISTRAL_API_KEY missing in secrets\")\n",
    "        MISTRAL_CLIENT = Mistral(api_key=api_key)\n",
    "    return MISTRAL_CLIENT\n",
    "\n",
    "def call_llm_gemini(prompt: str, model: str, timeout: int = 60) -> str:\n",
    "    try:\n",
    "        if model not in GENAI_MODELS:\n",
    "            api_key = GOOGLE_API_KEY\n",
    "            if not api_key:\n",
    "                raise RuntimeError(\"GOOGLE_API_KEY missing in secrets\")\n",
    "            genai.configure(api_key=api_key)\n",
    "            GENAI_MODELS[model] = genai.GenerativeModel(model)\n",
    "        resp = GENAI_MODELS[model].generate_content(prompt)\n",
    "        return (getattr(resp, \"text\", \"\") or \"\").strip()\n",
    "    except Exception as e:\n",
    "        logger.error(\"[Gemini %s] call failed: %s\", model, e)\n",
    "        return \"\"\n",
    "\n",
    "# -------------------------\n",
    "# Basic logging\n",
    "# -------------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"resume_ranker_app\")\n",
    "\n",
    "# -------------------------\n",
    "# Configuration dataclasses\n",
    "# -------------------------\n",
    "@dataclass\n",
    "class Weights:\n",
    "    dense: float = 0.15\n",
    "    keyword: float = 0.05\n",
    "    skill: float = 0.45\n",
    "    experience: float = 0.20\n",
    "    domain: float = 0.15\n",
    "    recency: float = 0.10\n",
    "    metadata: float = 0.05\n",
    "    projects: float = 0.05\n",
    "    education: float = 0.05\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    llm_model: str = \"llama3.2:3b-instruct-q4_K_M\"\n",
    "    llm_base_url: str = \"http://127.0.0.1:11434\"\n",
    "    embed_model: str = \"BAAI/bge-large-en-v1.5\"\n",
    "    embed_batch: int = 32\n",
    "    weights: Weights = field(default_factory=Weights)\n",
    "    bm25_min_doc_freq: int = 1\n",
    "\n",
    "cfg = PipelineConfig()\n",
    "\n",
    "# -------------------------\n",
    "# Cached resource loaders\n",
    "# -------------------------\n",
    "@st.cache_resource\n",
    "def load_main_embedder(model_name: str = None):\n",
    "    model = model_name or cfg.embed_model\n",
    "    device = \"cuda\" if __import__(\"torch\").cuda.is_available() else \"cpu\"\n",
    "    logger.info(\"Loading main embedder '%s' on device=%s\", model, device)\n",
    "    return SentenceTransformer(model, device=device)\n",
    "\n",
    "@st.cache_resource\n",
    "def load_skill_embedder(model_name: str = \"BAAI/bge-small-en-v1.5\"):\n",
    "    # keep skill embedder on CPU to conserve GPU memory\n",
    "    device = \"cpu\"\n",
    "    logger.info(\"Loading skill embedder '%s' on device=%s\", model_name, device)\n",
    "    return SentenceTransformer(model_name, device=device)\n",
    "\n",
    "@st.cache_resource\n",
    "def create_faiss_index(dim: int):\n",
    "    logger.info(\"Initializing FAISS IndexFlatIP (dim=%s)\", dim)\n",
    "    return faiss.IndexFlatIP(dim)\n",
    "\n",
    "# -------------------------\n",
    "# Hybrid Skill Normalizer (uses cached skill embedder)\n",
    "# -------------------------\n",
    "class HybridSkillNormalizer:\n",
    "    def __init__(self, llm_model: str = None, embed_model: str = None, threshold: float = 0.82):\n",
    "        self.llm_model = llm_model or cfg.llm_model\n",
    "        self.threshold = threshold\n",
    "        embed_model = embed_model or \"BAAI/bge-small-en-v1.5\"\n",
    "        self.embedder = load_skill_embedder(embed_model)\n",
    "        self.cache: Dict[str, np.ndarray] = {}\n",
    "        self.alias_map: Dict[str, str] = {}\n",
    "        self.reverse_groups: Dict[str, List[str]] = {}\n",
    "\n",
    "    def _llm_normalize(self, skill: str) -> str:\n",
    "        prompt = f\"Normalize the following skill into a concise canonical skill token. Return only the canonical skill name:\\n\\\"{skill}\\\"\"\n",
    "        try:\n",
    "            if not getattr(cfg, \"llm_base_url\", None):\n",
    "                return skill.strip().lower()\n",
    "            url = cfg.llm_base_url.rstrip(\"/\") + \"/api/chat\"\n",
    "            payload = {\"model\": self.llm_model, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"stream\": False}\n",
    "            r = httpx.post(url, json=payload, timeout=20)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            out = \"\"\n",
    "            if isinstance(data, dict):\n",
    "                if \"message\" in data and isinstance(data[\"message\"], dict):\n",
    "                    out = data[\"message\"].get(\"content\", \"\")\n",
    "                elif \"response\" in data:\n",
    "                    out = data.get(\"response\", \"\")\n",
    "                else:\n",
    "                    out = str(data)\n",
    "            else:\n",
    "                out = str(data)\n",
    "            out = out.splitlines()[0].strip().lower()\n",
    "            out = re.sub(r\"[^a-z0-9_\\-\\s\\.]+\", \"\", out)\n",
    "            if out == \"\":\n",
    "                return skill.strip().lower()\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            logger.debug(\"LLM normalization failed for '%s': %s\", skill, e)\n",
    "            return skill.strip().lower()\n",
    "\n",
    "    def _embed(self, text: str) -> np.ndarray:\n",
    "        v = self.embedder.encode([text], normalize_embeddings=True)\n",
    "        return np.asarray(v[0], dtype=np.float32)\n",
    "\n",
    "    def _find_similar(self, vec: np.ndarray):\n",
    "        if not self.cache:\n",
    "            return None, 0.0\n",
    "        keys = list(self.cache.keys())\n",
    "        mat = np.vstack([self.cache[k] for k in keys])\n",
    "        sims = util.cos_sim(vec, mat)[0]\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        return keys[best_idx], float(sims[best_idx])\n",
    "\n",
    "    def normalize_skill(self, s: str) -> str:\n",
    "        if not s or not isinstance(s, str):\n",
    "            return \"\"\n",
    "        original = s.strip().lower()\n",
    "        if original in self.alias_map:\n",
    "            return self.alias_map[original]\n",
    "        cleaned = self._llm_normalize(original)\n",
    "        vec = self._embed(cleaned)\n",
    "        best, score = self._find_similar(vec)\n",
    "        if best and score >= self.threshold:\n",
    "            self.alias_map[original] = best\n",
    "            self.reverse_groups.setdefault(best, []).append(original)\n",
    "            return best\n",
    "        self.cache[cleaned] = vec\n",
    "        self.alias_map[original] = cleaned\n",
    "        self.reverse_groups.setdefault(cleaned, []).append(original)\n",
    "        return cleaned\n",
    "\n",
    "    def normalize_list(self, skills: List[str]) -> List[str]:\n",
    "        out: List[str] = []\n",
    "        seen = set()\n",
    "        for s in skills or []:\n",
    "            if not isinstance(s, str):\n",
    "                continue\n",
    "            try:\n",
    "                canon = self.normalize_skill(s)\n",
    "            except Exception:\n",
    "                canon = s.strip().lower()\n",
    "            if canon and canon not in seen:\n",
    "                seen.add(canon)\n",
    "                out.append(canon)\n",
    "        return out\n",
    "\n",
    "@st.cache_resource\n",
    "def get_skill_normalizer():\n",
    "    return HybridSkillNormalizer(embed_model=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "SKILL_NORMALIZER: HybridSkillNormalizer = get_skill_normalizer()\n",
    "\n",
    "# -------------------------\n",
    "# Document reading helpers\n",
    "# -------------------------\n",
    "def read_document(blob: Dict[str, Any]) -> str:\n",
    "    name = blob.get(\"name\", \"\").lower()\n",
    "    data = blob.get(\"bytes\", b\"\")\n",
    "    if not data:\n",
    "        return \"\"\n",
    "    if name.endswith(\".txt\"):\n",
    "        try:\n",
    "            return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            return data.decode(\"latin-1\", errors=\"ignore\")\n",
    "    if name.endswith(\".pdf\"):\n",
    "        try:\n",
    "            stream = io.BytesIO(data)\n",
    "            reader = PdfReader(stream)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += (page.extract_text() or \"\") + \"\\n\"\n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            logger.warning(\"PDF extraction error for %s: %s\", name, e)\n",
    "            return \"\"\n",
    "    try:\n",
    "        return data.decode(\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# -------------------------\n",
    "# LLM call helper\n",
    "# -------------------------\n",
    "def call_llm(prompt: str, model: str = None, timeout: int = 60) -> str:\n",
    "    model = model or cfg.llm_model\n",
    "    url = cfg.llm_base_url.rstrip(\"/\") + \"/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"num_predict\": 512, \"temperature\": 0.1, \"top_p\": 0.9},\n",
    "    }\n",
    "    try:\n",
    "        r = httpx.post(url, json=payload, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        if isinstance(data, dict):\n",
    "            if \"message\" in data and isinstance(data[\"message\"], dict):\n",
    "                return data[\"message\"].get(\"content\", \"\")\n",
    "            if \"response\" in data:\n",
    "                return data[\"response\"]\n",
    "        return str(data)\n",
    "    except Exception as e:\n",
    "        logger.error(\"[LLM] call failed: %s\", e)\n",
    "        return \"\"\n",
    "\n",
    "# -------------------------\n",
    "# Safe JSON extraction\n",
    "# -------------------------\n",
    "def safe_json_extract(raw: str) -> Dict[str, Any]:\n",
    "    if not raw:\n",
    "        return {}\n",
    "    raw = raw.strip()\n",
    "    if raw.startswith(\"```\"):\n",
    "        lines = []\n",
    "        for line in raw.splitlines():\n",
    "            if line.strip().startswith(\"```\"):\n",
    "                continue\n",
    "            lines.append(line)\n",
    "        raw = \"\\n\".join(lines)\n",
    "    start = raw.find(\"{\")\n",
    "    end = raw.rfind(\"}\")\n",
    "    if start >= 0 and end > start:\n",
    "        candidate = raw[start : end + 1]\n",
    "        try:\n",
    "            return json.loads(candidate)\n",
    "        except Exception:\n",
    "            try:\n",
    "                fixed = candidate.replace(\"'\", '\"')\n",
    "                fixed = re.sub(r\",\\s*}\", \"}\", fixed)\n",
    "                fixed = re.sub(r\",\\s*]\", \"]\", fixed)\n",
    "                return json.loads(fixed)\n",
    "            except Exception:\n",
    "                return {}\n",
    "    return {}\n",
    "\n",
    "# -------------------------\n",
    "# Job extraction\n",
    "# -------------------------\n",
    "def extract_job_struct(text: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "You are a JSON extractor. From the job posting text below extract a JSON object with fields:\n",
    "- job_title (string)\n",
    "- summary (short string)\n",
    "- must (list of strings)\n",
    "- important (list of strings)\n",
    "- nice (list of strings)\n",
    "- implicit (list of strings)\n",
    "- domain (list of domains/tags)\n",
    "\n",
    "Return only valid JSON. Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    raw = call_llm_gemini(prompt, model=cfg.llm_model_resume, timeout=90)\n",
    "    parsed = safe_json_extract(raw)\n",
    "    raw_tiers = {\n",
    "        \"must\": parsed.get(\"must\", parsed.get(\"must_have\", [])) or [],\n",
    "        \"important\": parsed.get(\"important\", parsed.get(\"important_skills\", [])) or [],\n",
    "        \"nice\": parsed.get(\"nice\", parsed.get(\"nice_to_have\", [])) or [],\n",
    "        \"implicit\": parsed.get(\"implicit\", []) or [],\n",
    "    }\n",
    "    norm_tiers = {tier: SKILL_NORMALIZER.normalize_list(raw_tiers.get(tier, [])) for tier in [\"must\", \"important\", \"nice\", \"implicit\"]}\n",
    "    return {\n",
    "        \"job_title\": parsed.get(\"job_title\", \"\").strip(),\n",
    "        \"summary\": parsed.get(\"summary\", \"\").strip(),\n",
    "        \"must\": norm_tiers[\"must\"],\n",
    "        \"important\": norm_tiers[\"important\"],\n",
    "        \"nice\": norm_tiers[\"nice\"],\n",
    "        \"implicit\": norm_tiers[\"implicit\"],\n",
    "        \"domain\": parsed.get(\"domain\", []) or [],\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Basic regex resume parser\n",
    "# -------------------------\n",
    "EMAIL_RE = re.compile(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\")\n",
    "YEARS_RE = re.compile(r\"(\\d{4})[\u2013-](\\d{4}|present|Present|Now|now)\")\n",
    "\n",
    "def regex_extract_basic(text: str) -> Dict[str, Any]:\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "    name = \"\"\n",
    "    if lines:\n",
    "        first = lines[0]\n",
    "        if len(first.split()) <= 4 and re.search(r\"[A-Za-z]\", first):\n",
    "            name = first\n",
    "        else:\n",
    "            for i, ln in enumerate(lines):\n",
    "                if EMAIL_RE.search(ln) and i > 0:\n",
    "                    name = lines[i - 1]\n",
    "                    break\n",
    "    email_match = EMAIL_RE.search(text)\n",
    "    email = email_match.group(0) if email_match else \"\"\n",
    "    skill_candidates = set()\n",
    "    for ln in lines:\n",
    "        if re.search(r\"\\b(Skill|Skills|TECH|TECHNICAL|Technologies)\\b\", ln, re.I) or (\",\" in ln and len(ln.split(\",\")) <= 15):\n",
    "            for token in re.split(r\"[,:;\\|\\n]\", ln):\n",
    "                token = token.strip()\n",
    "                if token and len(token) < 60:\n",
    "                    skill_candidates.add(token)\n",
    "    yrs = 0.0\n",
    "    years = YEARS_RE.findall(text)\n",
    "    if years:\n",
    "        tot = 0\n",
    "        count = 0\n",
    "        for s, e in years:\n",
    "            try:\n",
    "                sy = int(s)\n",
    "                ey = datetime.utcnow().year if re.match(r\"(?i)present|now\", e) else int(e)\n",
    "                tot += max(0, ey - sy)\n",
    "                count += 1\n",
    "            except:\n",
    "                pass\n",
    "        if count:\n",
    "            yrs = tot / count\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"email\": email,\n",
    "        \"skills\": sorted(list(skill_candidates))[:200],\n",
    "        \"years_est\": yrs,\n",
    "        \"raw\": text,\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# LLM-based resume extraction\n",
    "# -------------------------\n",
    "def extract_resume_struct(text: str, use_llm=True) -> Dict[str, Any]:\n",
    "    basic = regex_extract_basic(text)\n",
    "    if use_llm:\n",
    "        prompt = f\"\"\"\n",
    "You are an extractor. Given the resume text, return a JSON with:\n",
    "- name\n",
    "- email\n",
    "- skills (list of strings)\n",
    "- experience (list of {{company, title, start, end, years}})\n",
    "- projects (list of short descriptions)\n",
    "- domain (list of tags)\n",
    "- last_active (year or string)\n",
    "- years_est (float)\n",
    "Return only JSON. Resume:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "        raw = call_llm(prompt, model=cfg.llm_model, timeout=90)\n",
    "        parsed = safe_json_extract(raw)\n",
    "        skills = parsed.get(\"skills\") or basic.get(\"skills\") or []\n",
    "        skills = [s.strip() for s in skills if isinstance(s, str) and s.strip()]\n",
    "        skills = SKILL_NORMALIZER.normalize_list(skills)\n",
    "        skills_bool = {s: True for s in skills}\n",
    "        return {\n",
    "            \"name\": parsed.get(\"name\") or basic.get(\"name\") or \"\",\n",
    "            \"email\": parsed.get(\"email\") or basic.get(\"email\") or \"\",\n",
    "            \"skills\": skills,\n",
    "            \"skills_bool\": skills_bool,\n",
    "            \"experience\": parsed.get(\"experience\", []),\n",
    "            \"projects\": parsed.get(\"projects\", []),\n",
    "            \"domain\": parsed.get(\"domain\", []),\n",
    "            \"last_active\": parsed.get(\"last_active\") or \"\",\n",
    "            \"years_est\": parsed.get(\"years_est\") or basic.get(\"years_est\") or 0,\n",
    "            \"raw\": text,\n",
    "        }\n",
    "    else:\n",
    "        skills = SKILL_NORMALIZER.normalize_list(basic.get(\"skills\", []))\n",
    "        return {\n",
    "            \"name\": basic.get(\"name\", \"\"),\n",
    "            \"email\": basic.get(\"email\", \"\"),\n",
    "            \"skills\": skills,\n",
    "            \"skills_bool\": {s: True for s in skills},\n",
    "            \"experience\": [],\n",
    "            \"projects\": [],\n",
    "            \"domain\": [],\n",
    "            \"last_active\": \"\",\n",
    "            \"years_est\": basic.get(\"years_est\", 0),\n",
    "            \"raw\": text,\n",
    "        }\n",
    "\n",
    "# -------------------------\n",
    "# Embedding + FAISS services (cached)\n",
    "# -------------------------\n",
    "class EmbeddingService:\n",
    "    def __init__(self, model_name: str = None):\n",
    "        model_name = model_name or cfg.embed_model\n",
    "        self.model = load_main_embedder(model_name)\n",
    "        self.dim = self.model.get_sentence_embedding_dimension()\n",
    "        logger.info(\"Embedding dim: %s\", self.dim)\n",
    "        self._faiss_index = None\n",
    "\n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        if not texts:\n",
    "            return np.zeros((0, self.dim), dtype=np.float32)\n",
    "        vecs = self.model.encode(texts, batch_size=cfg.embed_batch, convert_to_numpy=True, normalize_embeddings=True)\n",
    "        return vecs.astype(np.float32)\n",
    "\n",
    "    def create_faiss(self):\n",
    "        if self._faiss_index is None:\n",
    "            self._faiss_index = create_faiss_index(self.dim)\n",
    "        return self._faiss_index\n",
    "\n",
    "@st.cache_resource\n",
    "def get_embedding_service():\n",
    "    return EmbeddingService(cfg.embed_model)\n",
    "\n",
    "EMB: EmbeddingService = get_embedding_service()\n",
    "\n",
    "class FAISSService:\n",
    "    def __init__(self, dim: int):\n",
    "        self.dim = dim\n",
    "        self.index = create_faiss_index(dim)\n",
    "        self.ids: List[str] = []\n",
    "        self.meta: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = create_faiss_index(self.dim)\n",
    "        self.ids = []\n",
    "        self.meta = {}\n",
    "\n",
    "    def add(self, vectors: np.ndarray, payloads: List[Dict[str, Any]]):\n",
    "        if vectors is None or vectors.shape[0] == 0:\n",
    "            return\n",
    "        vecs = np.asarray(vectors, dtype=np.float32)\n",
    "        if vecs.ndim == 1:\n",
    "            vecs = vecs.reshape(1, -1)\n",
    "        self.index.add(vecs)\n",
    "        for p in payloads:\n",
    "            self.ids.append(p[\"id\"])\n",
    "            self.meta[p[\"id\"]] = p\n",
    "\n",
    "    def search(self, query_vec: np.ndarray, top_k: int = 10):\n",
    "        if self.index.ntotal == 0:\n",
    "            return []\n",
    "        q = np.asarray(query_vec, dtype=np.float32).reshape(1, -1)\n",
    "        D, I = self.index.search(q, top_k)\n",
    "        hits = []\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            # Guard against invalid indices that can appear in FAISS results\n",
    "            if idx < 0 or idx >= len(self.ids):\n",
    "                continue\n",
    "            rid = self.ids[idx]\n",
    "            hits.append({\"id\": rid, \"payload\": self.meta.get(rid, {}), \"score\": float(score)})\n",
    "        return hits\n",
    "\n",
    "FA = FAISSService(EMB.dim)\n",
    "\n",
    "# -------------------------\n",
    "# BM25 helper\n",
    "# -------------------------\n",
    "def safe_build_bm25(docs: List[str]):\n",
    "    try:\n",
    "        tokenized = [re.findall(r\"\\w+\", d.lower()) for d in docs]\n",
    "        if not any(tokenized):\n",
    "            return None\n",
    "        return BM25Okapi(tokenized)\n",
    "    except Exception as e:\n",
    "        logger.warning(\"BM25 build failed: %s\", e)\n",
    "        return None\n",
    "\n",
    "# -------------------------\n",
    "# Scoring helpers\n",
    "# -------------------------\n",
    "def normalize_scores(raw: List[float]) -> List[float]:\n",
    "    arr = np.array(raw, dtype=np.float32)\n",
    "    if arr.size == 0:\n",
    "        return []\n",
    "    minv, maxv = float(np.min(arr)), float(np.max(arr))\n",
    "    if abs(maxv - minv) < 1e-9:\n",
    "        return [1.0 for _ in arr.tolist()]\n",
    "    norm = (arr - minv) / (maxv - minv)\n",
    "    return norm.tolist()\n",
    "\n",
    "def skill_tier_score(candidate_skills: List[str], job_tiers: Dict[str, List[str]]) -> float:\n",
    "    if not candidate_skills:\n",
    "        return 0.0\n",
    "    cand = {SKILL_NORMALIZER.normalize_skill(s) for s in candidate_skills if s}\n",
    "    cand.discard(\"\")\n",
    "    must = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"must\", []))\n",
    "    imp = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"important\", []))\n",
    "    nice = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"nice\", []))\n",
    "    impl = SKILL_NORMALIZER.normalize_list(job_tiers.get(\"implicit\", []))\n",
    "    tier_weights = {\"must\": 1.0, \"important\": 0.7, \"nice\": 0.3, \"implicit\": 0.15}\n",
    "    def coverage(tier_skills: List[str]) -> float:\n",
    "        if not tier_skills:\n",
    "            return 0.0\n",
    "        present = sum(1.0 for s in tier_skills if s in cand)\n",
    "        return present / max(1, len(tier_skills))\n",
    "    must_cov = coverage(must)\n",
    "    imp_cov = coverage(imp)\n",
    "    nice_cov = coverage(nice)\n",
    "    impl_cov = coverage(impl)\n",
    "    total_weight = ((tier_weights[\"must\"] if must else 0.0) + (tier_weights[\"important\"] if imp else 0.0) + (tier_weights[\"nice\"] if nice else 0.0) + (tier_weights[\"implicit\"] if impl else 0.0))\n",
    "    if total_weight <= 0:\n",
    "        base_score = 0.0\n",
    "    else:\n",
    "        base_score = (must_cov * tier_weights[\"must\"] + imp_cov * tier_weights[\"important\"] + nice_cov * tier_weights[\"nice\"] + impl_cov * tier_weights[\"implicit\"]) / total_weight\n",
    "    if must:\n",
    "        missing = sum(1 for s in must if s not in cand)\n",
    "        missing_fraction = missing / max(1, len(must))\n",
    "        penalty = 0.5 * missing_fraction\n",
    "        final_score = base_score * (1.0 - penalty)\n",
    "    else:\n",
    "        final_score = base_score\n",
    "    return float(max(min(final_score, 1.0), 0.0))\n",
    "\n",
    "def domain_score(candidate_domains: List[str], job_domains: List[str]) -> float:\n",
    "    if not job_domains:\n",
    "        return 0.0\n",
    "    c = {d.lower() for d in (candidate_domains or [])}\n",
    "    j = {d.lower() for d in (job_domains or [])}\n",
    "    if not j:\n",
    "        return 0.0\n",
    "    return len(c & j) / max(1, len(j))\n",
    "\n",
    "def experience_score(years: float) -> float:\n",
    "    return min(max(float(years or 0), 0.0) / 10.0, 1.0)\n",
    "\n",
    "def recency_score(last_active) -> float:\n",
    "    try:\n",
    "        y = int(str(last_active).strip())\n",
    "        gap = max(0, datetime.utcnow().year - y)\n",
    "        if gap <= 1:\n",
    "            return 1.0\n",
    "        if gap <= 3:\n",
    "            return 0.8\n",
    "        if gap <= 5:\n",
    "            return 0.5\n",
    "        return 0.2\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "def metadata_score(structured: Dict[str, Any]) -> float:\n",
    "    score = 0.0\n",
    "    score += 0.5 if structured.get(\"email\") else 0.0\n",
    "    score += 0.5 if structured.get(\"projects\") else 0.0\n",
    "    return min(score, 1.0)\n",
    "\n",
    "def projects_score(structured: Dict[str, Any]) -> float:\n",
    "    projects = structured.get(\"projects\") or []\n",
    "    if not projects:\n",
    "        return 0.0\n",
    "    n = len(projects)\n",
    "    return float(min(n / 5.0, 1.0))\n",
    "\n",
    "def education_score(structured: Dict[str, Any]) -> float:\n",
    "    text = (structured.get(\"raw\") or \"\") + \"\\n\" + \" \".join(structured.get(\"projects\", []))\n",
    "    text = text.lower()\n",
    "    if \"phd\" in text or \"ph.d\" in text:\n",
    "        return 1.0\n",
    "    if \"master\" in text or \"msc\" in text or \"m.sc\" in text:\n",
    "        return 0.8\n",
    "    if \"bachelor\" in text or \"bsc\" in text or \"b.sc\" in text:\n",
    "        return 0.6\n",
    "    if \"diploma\" in text or \"associate\" in text:\n",
    "        return 0.4\n",
    "    return 0.0\n",
    "\n",
    "# -------------------------\n",
    "# Explainability\n",
    "# -------------------------\n",
    "def generate_explanation(job_struct: Dict[str, Any], candidate: Dict[str, Any], components: Dict[str, float]) -> Dict[str, Any]:\n",
    "    job_tiers = {\n",
    "        \"must\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"must\", [])),\n",
    "        \"important\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"important\", [])),\n",
    "        \"nice\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"nice\", [])),\n",
    "        \"implicit\": SKILL_NORMALIZER.normalize_list(job_struct.get(\"implicit\", [])),\n",
    "    }\n",
    "    structured = candidate.get(\"structured\", candidate)\n",
    "    cand_skills = SKILL_NORMALIZER.normalize_list(structured.get(\"skills\", []))\n",
    "    cand_set = set(cand_skills)\n",
    "    strengths = sorted([s for s in job_tiers.get(\"must\", []) if s in cand_set])\n",
    "    gaps = sorted([s for s in job_tiers.get(\"must\", []) if s not in cand_set])\n",
    "    projects = structured.get(\"projects\", [])\n",
    "    exp_summary = f\"{structured.get('years_est', 0)} years; last active: {structured.get('last_active','N/A')}\"\n",
    "    breakdown = components\n",
    "    weight_table = {\n",
    "        \"dense\": cfg.weights.dense,\n",
    "        \"keyword\": cfg.weights.keyword,\n",
    "        \"skill\": cfg.weights.skill,\n",
    "        \"experience\": cfg.weights.experience,\n",
    "        \"domain\": cfg.weights.domain,\n",
    "        \"recency\": cfg.weights.recency,\n",
    "        \"projects\": cfg.weights.projects,\n",
    "        \"education\": cfg.weights.education,\n",
    "        \"metadata\": cfg.weights.metadata,\n",
    "    }\n",
    "    overall = sum(components[k] * weight_table.get(k, 0.0) for k in components)\n",
    "    if overall >= 0.75:\n",
    "        confidence = \"high\"\n",
    "    elif overall >= 0.5:\n",
    "        confidence = \"medium\"\n",
    "    else:\n",
    "        confidence = \"low\"\n",
    "    prompt = f\"\"\"\n",
    "You are an experienced engineer and hiring panelist reviewing a candidate's RESUME.\n",
    "The job description is context; your priority is the candidate's actual experience and how it matches this specific role.\n",
    "\n",
    "Job (context):\n",
    "- Title: {job_struct.get('job_title') or ''}\n",
    "- Summary: {job_struct.get('summary') or ''}\n",
    "\n",
    "Candidate (focus of the review):\n",
    "- Name: {structured.get('name') or candidate.get('name') or ''}\n",
    "- Normalized skills: {cand_skills}\n",
    "- Projects (from resume): {projects}\n",
    "- Experience & recency: {exp_summary}\n",
    "\n",
    "Analysis data:\n",
    "- Component scores (0\u20131): {breakdown}\n",
    "- Weights: {weight_table}\n",
    "- Overall fit score (0\u20131): {overall:.3f}\n",
    "- Job must-have strengths (present in resume): {strengths}\n",
    "- Job must-have gaps (missing from resume): {gaps}\n",
    "- Confidence bucket: {confidence}\n",
    "\n",
    "Write a short, job-specific review (3\u20135 sentences) as if you were giving feedback to a hiring manager:\n",
    "1. Describe the candidate's profile based on the RESUME (tech/domain stack, type of projects, seniority).\n",
    "2. Relate how this profile lines up with the job at a high level (strong match, partial match, or stretch) for THIS specific role.\n",
    "3. Explicitly mention 2\u20134 concrete strengths from their resume and 1\u20132 key gaps relevant to the job.\n",
    "4. Mention the overall fit score (0\u20131) and confidence level ({confidence}) in a natural way.\n",
    "Avoid boilerplate phrases and be concise.\n",
    "\"\"\"\n",
    "    human_text = call_llm_gemini(prompt, model=cfg.llm_model_explain, timeout=45)\n",
    "    structured_out = {\n",
    "        \"strengths\": strengths,\n",
    "        \"gaps\": gaps,\n",
    "        \"experience_summary\": exp_summary,\n",
    "        \"projects\": projects,\n",
    "        \"score_breakdown\": breakdown,\n",
    "        \"weights\": weight_table,\n",
    "        \"overall\": float(overall),\n",
    "        \"confidence\": confidence,\n",
    "    }\n",
    "    return {\"structured\": structured_out, \"human\": human_text}\n",
    "\n",
    "# -------------------------\n",
    "# Ranking pipeline\n",
    "# -------------------------\n",
    "def rank_hybrid(job: Dict[str, Any], resumes: List[Dict[str, Any]], cfg: PipelineConfig, top_n: int = 10):\n",
    "    resume_texts = [r[\"raw\"] for r in resumes]\n",
    "    resume_vecs = EMB.encode(resume_texts) if len(resume_texts) else np.zeros((0, EMB.dim), dtype=np.float32)\n",
    "    job_vec = EMB.encode([job[\"raw\"]])[0] if job[\"raw\"].strip() else np.zeros((EMB.dim,), dtype=np.float32)\n",
    "    FA.reset()\n",
    "    payloads = [{\"id\": r[\"id\"], \"structured\": r[\"structured\"], \"skills\": r.get(\"skills\", [])} for r in resumes]\n",
    "    FA.add(resume_vecs, payloads)\n",
    "    dense_raw = [0.0] * len(resumes)\n",
    "    hits = FA.search(job_vec, top_k=len(resumes))\n",
    "    id2idx = {r[\"id\"]: i for i, r in enumerate(resumes)}\n",
    "    for h in hits:\n",
    "        idx = id2idx.get(h[\"id\"])\n",
    "        if idx is not None:\n",
    "            dense_raw[idx] = h[\"score\"]\n",
    "    dense_norm = normalize_scores(dense_raw)\n",
    "    bm25 = safe_build_bm25(resume_texts)\n",
    "    if bm25:\n",
    "        job_tokens = re.findall(r\"\\w+\", job[\"raw\"].lower())\n",
    "        bm_raw = bm25.get_scores(job_tokens)\n",
    "    else:\n",
    "        bm_raw = [0.0] * len(resumes)\n",
    "    skill_raw, domain_raw, exp_raw, rec_raw, proj_raw, edu_raw, meta_raw = [], [], [], [], [], [], []\n",
    "    for r in resumes:\n",
    "        structured = r.get(\"structured\", {})\n",
    "        s = skill_tier_score(structured.get(\"skills\", []), {\n",
    "            \"must\": job[\"structured\"].get(\"must\", []),\n",
    "            \"important\": job[\"structured\"].get(\"important\", []),\n",
    "            \"nice\": job[\"structured\"].get(\"nice\", []),\n",
    "            \"implicit\": job[\"structured\"].get(\"implicit\", []),\n",
    "        })\n",
    "        d = domain_score(r.get(\"domain\", []), job[\"structured\"].get(\"domain\", []))\n",
    "        e = experience_score(r.get(\"years_est\", 0) or 0)\n",
    "        rc = recency_score(r.get(\"last_active\", \"\")) if r.get(\"last_active\") else recency_score(r.get(\"years_est\", 0))\n",
    "        p = projects_score(structured)\n",
    "        edu = education_score(structured)\n",
    "        m = metadata_score(structured)\n",
    "        skill_raw.append(s)\n",
    "        domain_raw.append(d)\n",
    "        exp_raw.append(e)\n",
    "        rec_raw.append(rc)\n",
    "        proj_raw.append(p)\n",
    "        edu_raw.append(edu)\n",
    "        meta_raw.append(m)\n",
    "    dense = dense_norm or [0.0] * len(resumes)\n",
    "    keyword = normalize_scores(bm_norm) or [0.0] * len(resumes)\n",
    "    skill = normalize_scores(skill_raw) or [0.0] * len(resumes)\n",
    "    domain = normalize_scores(domain_raw) or [0.0] * len(resumes)\n",
    "    experience = normalize_scores(exp_raw) or [0.0] * len(resumes)\n",
    "    recency = normalize_scores(rec_raw) or [0.0] * len(resumes)\n",
    "    projects = normalize_scores(proj_raw) or [0.0] * len(resumes)\n",
    "    education = normalize_scores(edu_raw) or [0.0] * len(resumes)\n",
    "    metadata = normalize_scores(meta_raw) or [0.0] * len(resumes)\n",
    "    final = []\n",
    "    W = cfg.weights\n",
    "    for i, r in enumerate(resumes):\n",
    "        components = {\n",
    "            \"dense\": float(dense[i]),\n",
    "            \"keyword\": float(keyword[i]),\n",
    "            \"skill\": float(skill[i]),\n",
    "            \"experience\": float(experience[i]),\n",
    "            \"domain\": float(domain[i]),\n",
    "            \"recency\": float(recency[i]),\n",
    "            \"projects\": float(projects[i]),\n",
    "            \"education\": float(education[i]),\n",
    "            \"metadata\": float(metadata[i]),\n",
    "        }\n",
    "        overall = (\n",
    "            components[\"dense\"] * W.dense\n",
    "            + components[\"keyword\"] * W.keyword\n",
    "            + components[\"skill\"] * W.skill\n",
    "            + components[\"experience\"] * W.experience\n",
    "            + components[\"domain\"] * W.domain\n",
    "            + components[\"recency\"] * W.recency\n",
    "            + components[\"projects\"] * W.projects\n",
    "            + components[\"education\"] * W.education\n",
    "            + components[\"metadata\"] * W.metadata\n",
    "        )\n",
    "        expl = generate_explanation(job[\"structured\"], r, components)\n",
    "        final.append(\n",
    "            {\n",
    "                \"id\": r[\"id\"],\n",
    "                \"name\": r[\"structured\"].get(\"name\", r.get(\"name\", \"\")),\n",
    "                \"overall\": float(overall),\n",
    "                \"components\": components,\n",
    "                \"explanation\": expl,\n",
    "            }\n",
    "        )\n",
    "    final_sorted = sorted(final, key=lambda x: x[\"overall\"], reverse=True)\n",
    "    return final_sorted[:top_n]\n",
    "\n",
    "# -------------------------\n",
    "# Assemble entities from uploaded blobs\n",
    "# -------------------------\n",
    "def assemble_entities_from_blobs(jd_blob: Dict[str, Any], resume_blobs: List[Dict[str, Any]]):\n",
    "    jd_text = read_document(jd_blob)\n",
    "    jd_struct = extract_job_struct(jd_text)\n",
    "    job = {\n",
    "        \"id\": jd_blob.get(\"name\", f\"job_{uuid.uuid4()}\"),\n",
    "        \"raw\": jd_text,\n",
    "        \"structured\": jd_struct,\n",
    "    }\n",
    "    resumes = []\n",
    "    for rb in resume_blobs:\n",
    "        txt = read_document(rb)\n",
    "        parsed = extract_resume_struct(txt)\n",
    "        resumes.append(\n",
    "            {\n",
    "                \"id\": rb.get(\"name\", f\"res_{uuid.uuid4()}\"),\n",
    "                \"raw\": txt,\n",
    "                \"skills\": parsed.get(\"skills\", []),\n",
    "                \"experiences\": parsed.get(\"experience\", []),\n",
    "                \"structured\": parsed,\n",
    "                \"name\": parsed.get(\"name\", rb.get(\"name\", \"\")),\n",
    "                \"domain\": parsed.get(\"domain\", []),\n",
    "                \"years_est\": parsed.get(\"years_est\", 0),\n",
    "                \"last_active\": parsed.get(\"last_active\", \"\"),\n",
    "            }\n",
    "        )\n",
    "    return job, resumes\n",
    "\n",
    "# -------------------------\n",
    "# Streamlit UI\n",
    "# -------------------------\n",
    "st.set_page_config(page_title=\"AI Resume Ranking System\", layout=\"wide\")\n",
    "st.title(\"\ud83c\udfaf Multi-Dimensional AI Resume Ranking System\")\n",
    "st.write(\"Upload a job description and resumes to generate ranked candidates\")\n",
    "st.markdown(\"---\")\n",
    "\n",
    "col1, col2 = st.columns([1, 2])\n",
    "\n",
    "with col1:\n",
    "    st.header(\"\ud83d\udcc1 Input Files\")\n",
    "    jd_file = st.file_uploader(\"\ud83d\udcc4 Upload Job Description\", type=[\"pdf\", \"txt\"])\n",
    "    res_files = st.file_uploader(\"\ud83e\uddd1\u200d\ud83d\udcbc Upload Candidate Resumes\", type=[\"pdf\", \"txt\"], accept_multiple_files=True)\n",
    "\n",
    "    with st.expander(\"\u2699\ufe0f Advanced Settings\"):\n",
    "        top_n = st.slider(\"Top N candidates to show:\", 1, 20, 10)\n",
    "        st.write(\"LLM model:\", cfg.llm_model)\n",
    "        st.write(\"Embedding model:\", cfg.embed_model)\n",
    "        st.markdown(\"**Weighting (0.0 - 1.0)**\")\n",
    "        cfg.weights.dense = st.slider(\"Dense similarity weight\", 0.0, 1.0, cfg.weights.dense, 0.05)\n",
    "        cfg.weights.keyword = st.slider(\"BM25 keyword weight\", 0.0, 1.0, cfg.weights.keyword, 0.05)\n",
    "        cfg.weights.skill = st.slider(\"Skill tier weight\", 0.0, 1.0, cfg.weights.skill, 0.05)\n",
    "        cfg.weights.experience = st.slider(\"Experience weight\", 0.0, 1.0, cfg.weights.experience, 0.05)\n",
    "        cfg.weights.domain = st.slider(\"Domain weight\", 0.0, 1.0, cfg.weights.domain, 0.05)\n",
    "        cfg.weights.recency = st.slider(\"Recency weight\", 0.0, 1.0, cfg.weights.recency, 0.05)\n",
    "        cfg.weights.projects = st.slider(\"Projects weight\", 0.0, 1.0, cfg.weights.projects, 0.05)\n",
    "        cfg.weights.education = st.slider(\"Education weight\", 0.0, 1.0, cfg.weights.education, 0.05)\n",
    "        cfg.weights.metadata = st.slider(\"Metadata weight\", 0.0, 1.0, cfg.weights.metadata, 0.05)\n",
    "\n",
    "    run_button = st.button(\"\ud83d\ude80 Run Candidate Ranking\")\n",
    "\n",
    "with col2:\n",
    "    if run_button:\n",
    "        if not jd_file:\n",
    "            st.error(\"Please upload a job description.\")\n",
    "            st.stop()\n",
    "        if not res_files:\n",
    "            st.error(\"Please upload at least one resume.\")\n",
    "            st.stop()\n",
    "\n",
    "        st.info(\"\u23f3 Running full hybrid pipeline (LLM extraction + embeddings + ranking)...\")\n",
    "\n",
    "        jd_blob = {\"name\": jd_file.name, \"bytes\": jd_file.read()}\n",
    "        resume_blobs = [{\"name\": f.name, \"bytes\": f.read()} for f in res_files]\n",
    "\n",
    "        try:\n",
    "            job, resumes = assemble_entities_from_blobs(jd_blob, resume_blobs)\n",
    "            ranked = rank_hybrid(job, resumes, cfg, top_n=top_n)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Pipeline failed: {e}\")\n",
    "            logger.exception(\"Pipeline error\")\n",
    "            st.stop()\n",
    "\n",
    "        st.success(\"\u2728 Ranking Completed!\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udccc Extracted Job Structure\")\n",
    "        st.json(job.get(\"structured\", {}))\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83c\udfc6 Ranked Candidates\")\n",
    "        df = pd.DataFrame([{\"Rank\": i + 1, \"Name\": r[\"name\"], \"Score\": round(r[\"overall\"], 3)} for i, r in enumerate(ranked)])\n",
    "        st.dataframe(df, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udd0d Candidate Explanations\")\n",
    "        for i, r in enumerate(ranked):\n",
    "            with st.expander(f\"#{i+1} \u2014 {r['name']} (Score: {round(r['overall'], 3)})\"):\n",
    "                comp_items = list(r[\"components\"].items())\n",
    "                comp_df = pd.DataFrame({\"Component\": [k for k, _ in comp_items], \"Score\": [float(v) for _, v in comp_items]})\n",
    "                radar_fig = px.line_polar(comp_df, r=\"Score\", theta=\"Component\", line_close=True, range_r=[0, 1], title=\"Component Radar\")\n",
    "                radar_fig.update_traces(fill=\"toself\")\n",
    "                st.plotly_chart(radar_fig, use_container_width=True)\n",
    "\n",
    "                overall_fit = r[\"explanation\"][\"structured\"].get(\"overall\", r[\"overall\"])\n",
    "                conf = r[\"explanation\"][\"structured\"].get(\"confidence\", \"unknown\")\n",
    "                st.write(f\"**Overall fit score:** {overall_fit:.3f}\")\n",
    "                st.write(f\"**Confidence:** {conf}\")\n",
    "\n",
    "                st.markdown(\"### \ud83d\udcdd Candidate Review\")\n",
    "                st.info(r[\"explanation\"].get(\"human\", \"\"))\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "        st.subheader(\"\ud83d\udce5 Download Results\")\n",
    "        st.download_button(\"Download JSON Report\", json.dumps(ranked, indent=2, default=str), file_name=\"ranking_output.json\", mime=\"application/json\")\n",
    "        st.download_button(\"Download CSV Rankings\", df.to_csv(index=False), file_name=\"ranking_output.csv\", mime=\"text/csv\")\n",
    "\n",
    "        st.caption(\"Built with Streamlit \u2022 FAISS \u2022 BGE Embeddings \u2022 LLM Explainability\")\n",
    "\n",
    "# End of file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}